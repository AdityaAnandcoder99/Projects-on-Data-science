# -*- coding: utf-8 -*-
"""task6_datascience_the_spark_foundation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DKUwm69bIz2rkd8Q8tVvGluBDg8veN4d
"""

# Commented out IPython magic to ensure Python compatibility.
# importing necessary libraries

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

data = pd.read_csv('/content/Iris.csv')

data.head()

data['Species'].unique()

species = {
    'Iris-setosa': 0,
    'Iris-versicolor':1,
    'Iris-virginica':2
}

data['Species'] = data['Species'].map(species)

data.Species.unique()

X = data.iloc[:, 1:5].values
y = data.iloc[:, 5].values

X.shape, y.shape

sns.countplot(y)
plt.show()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier()
model.fit(X_train ,y_train)

y_pred = model.predict(X_test)
y_pred

from sklearn import metrics

plt.figure(figsize = (9,7))
sns.heatmap(metrics.confusion_matrix(y_test, y_pred), xticklabels = data.iloc[:, 1:5].columns.values,  yticklabels = data.iloc[:, 1:5].columns.values, center = 0)
plt.show()

print(f"Precision: {metrics.precision_score(y_test, y_pred, average = 'macro')}")
print(f"Recall: {metrics.recall_score(y_test, y_pred, average = 'macro')}")
print(f"F1 Score: {metrics.f1_score(y_test, y_pred, average = 'macro')}")

from sklearn import tree

plt.figure(figsize = (15,10))
tree.plot_tree(model,
               feature_names = data.iloc[:, 1:5].columns.values,
               filled = True);
plt.title("Iris Data Decision Tree")
plt.show()